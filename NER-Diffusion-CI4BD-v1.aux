\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{goyal2010learning}
\citation{nadeau2007survey}
\citation{RatinovRo09}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related work}{2}}
\newlabel{sec:rw}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Named Entity Recognition}{2}}
\citation{tjong2003introduction}
\citation{derczynski2013microblog}
\citation{hovy2015user}
\citation{plank2015personality}
\citation{preoctiuc2015studying}
\citation{ritter2011named}
\citation{liu2011recognizing}
\citation{plank2014adapting}
\citation{rowe2015microposts2015}
\citation{baldwin2015shared}
\citation{cherryunreasonable}
\citation{han2011lexical}
\citation{fromreide2014crowdsourcing}
\citation{derczynski2015analysis}
\citation{guille2013information}
\citation{bakshy2012role}
\citation{romero2011differences}
\citation{yang2012we}
\citation{yang2012we}
\citation{goyal2010learning}
\citation{goyal2010learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Information Diffusion}{3}}
\citation{fang2013predicting}
\citation{huang2014temporal}
\citation{goyal2010learning}
\citation{ritter2011named}
\citation{baldwin2015shared}
\@writefile{toc}{\contentsline {section}{\numberline {III}Datasets preparation and NER}{4}}
\newlabel{sec:datasets_ner}{{III}{4}}
\citation{reddit-data}
\citation{kergl2014endogenesis}
\newlabel{fig:reddit-example}{{III}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example Reddit post. Note topic at the top, followed by comments, with conversations descending in a tree-like hierarchical fashion}}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Subreddit extraction}{5}}
\citation{kiss2006unsupervised}
\citation{o2010tweetmotif}
\citation{derczynski2015analysis}
\citation{ritter2011named}
\citation{tjong2003introduction}
\citation{ritter2011named}
\citation{baldwin2015shared}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}NER for Reddit}{6}}
\citation{brown1992class}
\citation{turian2009preliminary}
\citation{derczynski2016generalised}
\citation{derczynski2016generalised}
\citation{ratinov2009design}
\citation{derczynski2015usfd}
\citation{ritter2011named}
\citation{derczynski2015analysis}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Tuning entity recognition}{7}}
\citation{ritter2011named}
\citation{ritter2011named}
\citation{baldwin2015shared}
\citation{tjong2003introduction}
\citation{derczynski2015tune}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Results from applying different corpora blends as training data for named entity recognition.}}{8}}
\newlabel{tab:brown-tuning}{{I}{8}}
\citation{ritter2011named}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Scaling newswire (RCV) training data under three conditions: blended news and twitter clusters; blended news and twitter clusters with extra twitter training data; just new clusters.}}{9}}
\newlabel{fig:rcv-scaling}{{2}{9}}
\citation{derczynski2015analysis}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Top nine entities and their mention intensity over time}}{10}}
\newlabel{fig:entity-ts}{{\unhbox \voidb@x \hbox {III-D}}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}NER analysis}{10}}
\citation{leskovec2007patterns}
\citation{cordella2001improved}
\citation{leskovec2007patterns}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Entity Diffusion}{11}}
\newlabel{sec:diffusion}{{IV}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Entity Mention Cascades}{11}}
\citation{romero2011differences}
\newlabel{fig:cascade_shapes}{{4(a)}{12}}
\newlabel{sub@fig:cascade_shapes}{{(a)}{12}}
\newlabel{fig:rank_dist}{{4(b)}{12}}
\newlabel{sub@fig:rank_dist}{{(b)}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The top-20 cascade shapes are generally deep and narrow with little branching (Fig. 4(a)\hbox {}, while the cascade shape rank follows a power-law distribution (Fig. 4(b)\hbox {}.}}{12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Top-20 Cascade Shapes}}}{12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Cascade Shape Rank Distribution}}}{12}}
\newlabel{fig:entity_cascades}{{4}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Entity Adoption Post-$({k-1})^{th}$ Exposure}{12}}
\newlabel{def:exposure}{{2}{12}}
\citation{romero2011differences}
\citation{goyal2010learning}
\newlabel{fig:global_exposure_dist}{{5(a)}{13}}
\newlabel{sub@fig:global_exposure_dist}{{(a)}{13}}
\newlabel{fig:entity_exposure_dists}{{5(b)}{13}}
\newlabel{sub@fig:entity_exposure_dists}{{(b)}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The probability of a user adopting an entity as a function of $k$ prior exposures to the entity has a heavy-tailed distribution (Fig. 5(a)\hbox {}) that is consistent across all entities, including a sample of 9 random entities (Fig. 5(b)\hbox {}).}}{13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Exposure-Adoption Global Distribution}}}{13}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Sampled Entity Exposure-Adoption Distributions}}}{13}}
\newlabel{fig:exposure_dists}{{5}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Global Threshold Diffusion Model}{13}}
\newlabel{eq:joint_prob}{{2}{14}}
\newlabel{eq:action_prob}{{3}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}1}Additional Influence Dynamics - Entity-Adoption Constructs}{14}}
\citation{goyal2010learning}
\newlabel{fig:taus_hist}{{6(a)}{15}}
\newlabel{sub@fig:taus_hist}{{(a)}{15}}
\newlabel{fig:taus_loglog}{{6(b)}{15}}
\newlabel{sub@fig:taus_loglog}{{(b)}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The influence window ($\tau _{v,u}$) between two arbitrary users characterises the average time for an entity to propagate from $v$ to $u$. In hours, this value has a \emph  {right-skew} (Fig. 6(a)\hbox {}), while the log-log plot (Fig. 6(b)\hbox {}) of the relative frequency distribution demonstrates the heavy-tail nature of the distribution with a mean of $10,780$ hours ($\approx 449$ days $\approx 1.2$ years).}}{15}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Binned Frequency Distribution of $\tau _{v,u}$ values}}}{15}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Log-log Plot of the Binned $\tau _{v,u}$ distribution}}}{15}}
\newlabel{fig:taus}{{6}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Experiments}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}1}Experimental Setup}{16}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-D}1a}Deriving Adoption Probabilities}{16}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {IV-D}1b}Parallelising Processing}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}2}Results}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion and Future Work}{17}}
\newlabel{sec:discussions}{{V}{17}}
\citation{huang2014temporal}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Area under the Receiver Operator Characteristic Curve (ROC) values for the different probability settings and influence probability settings within the general threshold model.}}{18}}
\newlabel{tab:macro_results}{{II}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusions}{18}}
\newlabel{sec:conclusions}{{VI}{18}}
\citation{leskovec2007patterns}
\bibstyle{IEEEtran}
\bibdata{NER-Diffusion}
\bibcite{goyal2010learning}{1}
\bibcite{nadeau2007survey}{2}
\bibcite{RatinovRo09}{3}
\bibcite{tjong2003introduction}{4}
\bibcite{derczynski2013microblog}{5}
\bibcite{hovy2015user}{6}
\bibcite{plank2015personality}{7}
\bibcite{preoctiuc2015studying}{8}
\bibcite{ritter2011named}{9}
\bibcite{liu2011recognizing}{10}
\bibcite{plank2014adapting}{11}
\bibcite{rowe2015microposts2015}{12}
\@writefile{toc}{\contentsline {section}{References}{19}}
\bibcite{baldwin2015shared}{13}
\bibcite{cherryunreasonable}{14}
\bibcite{han2011lexical}{15}
\bibcite{fromreide2014crowdsourcing}{16}
\bibcite{derczynski2015analysis}{17}
\bibcite{guille2013information}{18}
\bibcite{bakshy2012role}{19}
\bibcite{romero2011differences}{20}
\bibcite{yang2012we}{21}
\bibcite{fang2013predicting}{22}
\bibcite{huang2014temporal}{23}
\bibcite{reddit-data}{24}
\bibcite{kergl2014endogenesis}{25}
\bibcite{kiss2006unsupervised}{26}
\bibcite{o2010tweetmotif}{27}
\bibcite{brown1992class}{28}
\bibcite{turian2009preliminary}{29}
\bibcite{derczynski2016generalised}{30}
\bibcite{ratinov2009design}{31}
\bibcite{derczynski2015usfd}{32}
\bibcite{derczynski2015tune}{33}
\bibcite{leskovec2007patterns}{34}
\bibcite{cordella2001improved}{35}
